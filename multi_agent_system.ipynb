{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3018e9a-ff7f-4960-8b85-368a20e454c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "import pprint\n",
    "load_dotenv()\n",
    "\n",
    "all_calls = []\n",
    "\n",
    "supervisor_llm = init_chat_model(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    model_provider='openai',\n",
    "    )\n",
    "\n",
    "\n",
    "rag_llm = init_chat_model(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    model_provider='openai',\n",
    ")\n",
    "\n",
    "calc_llm = init_chat_model(\n",
    "    model = 'gpt-4o-mini',\n",
    "    model_provider='openai',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool#(parse_docstring=True)\n",
    "def addition(a: float, b: float)->float:\n",
    "    \"\"\"\n",
    "    Adds two floating point numbers\n",
    "    Args:\n",
    "        a : First floating point number\n",
    "        b : Second floating point number\n",
    "    Returns:\n",
    "        a+b\n",
    "    \"\"\"\n",
    "\n",
    "    return a+b\n",
    "\n",
    "@tool#(parse_docstring=True)\n",
    "def subtraction(a:float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Performs subtraction of two floating point numbers.\n",
    "\n",
    "    Args:\n",
    "        a : First floating point number\n",
    "        b : Second floating point number\n",
    "    Returns:\n",
    "        a-b\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return a-b\n",
    "\n",
    "@tool#(parse_docstring=True)\n",
    "def multiplication(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Performs the product of two floating point numbers.\n",
    "    \n",
    "    Args:\n",
    "        a : First floating point number\n",
    "        b : Second floating point number\n",
    "    Returns:\n",
    "        a*b\n",
    "    \"\"\"\n",
    "\n",
    "    return a*b\n",
    "\n",
    "@tool#(parse_docstring=True)\n",
    "def division(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Performs the division of two floating point numbers.\n",
    "    \n",
    "    Args:\n",
    "        a : First floating point number\n",
    "        b : Second floating point number\n",
    "    Returns:\n",
    "        a/b\n",
    "    \"\"\"\n",
    "\n",
    "    return a/b\n",
    "\n",
    "calc_agent = create_agent(\n",
    "    model=calc_llm,\n",
    "    tools = [addition, subtraction, multiplication, division],\n",
    "    middleware=[TodoListMiddleware()],\n",
    "    system_prompt=\"You are an arithmetic agent. You have access to addition, subtraction, multiplication, and division tools \"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def retreive_augment_context(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retreives policy information about TCS company.\n",
    "    \n",
    "    Args:\n",
    "        query : Query about the company\n",
    "\n",
    "    Returns:\n",
    "        Returns the data retreived from the vector db to answer the query and augments the query.\n",
    "    \"\"\"\n",
    "    return f\"{query} : TCS has very strict policies about personal information\"\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_respond() -> str:\n",
    "    \"\"\"\n",
    "    Generates final response for the query.\n",
    "    Returns:\n",
    "        Returns the final response for the query.\n",
    "    \"\"\"\n",
    "    return \"TCS has very strict policies about personal information\"\n",
    "\n",
    "\n",
    "rag_agent = create_agent(\n",
    "    model=rag_llm,\n",
    "    tools = [retreive_augment_context, generate_respond],\n",
    "    middleware=[TodoListMiddleware()],\n",
    "    system_prompt=\"\"\"You are a RAG agent. Your task is to answer user queries that are relates to TCS policies.\n",
    "    Use the below tools to respond to all questions related to TCS policies.\n",
    "    Do not hallucinate, just invoke the tools to get the information regarding all TCS policies.\n",
    "    You have access to retreive_augment_context, and generate_respond tools \n",
    "    Do not add extra text other than what tools provide\"\"\"\n",
    ")\n",
    "\n",
    "@tool\n",
    "def calc_agent_tool(query: str):\n",
    "    \"\"\"\n",
    "    Capable of performing expression evaluation that contain addition, subtraction, multiplication, and division operations\n",
    "\n",
    "    Args:\n",
    "        query: Contains the expression to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        The final value after evaluation\n",
    "    \"\"\"\n",
    "    calc_resp =  calc_agent.invoke(\n",
    "        {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"human\",\n",
    "                \"content\" : query\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    all_calls.append(calc_resp)\n",
    "    return calc_resp['messages'][-1].content\n",
    "\n",
    "@tool\n",
    "def rag_policy_agent_tool(query: str):\n",
    "    \"\"\"\n",
    "    Capable of generating responses for any TCS related Policies.\n",
    "\n",
    "    Args:\n",
    "        query: Contains the query related to TCS Policies.\n",
    "\n",
    "    Returns:\n",
    "        The response to the query related to TCS Policies\n",
    "    \"\"\"\n",
    "    rag_resp =  rag_agent.invoke(\n",
    "        {\n",
    "            \"messages\": [{\n",
    "                \"role\": \"human\",\n",
    "                \"content\" : query\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    all_calls.append(rag_resp)\n",
    "    return rag_resp['messages'][-1].content\n",
    "\n",
    "supervisor_agent = create_agent(\n",
    "    model=supervisor_llm,\n",
    "    tools=[rag_policy_agent_tool, calc_agent_tool],\n",
    "    middleware=[TodoListMiddleware()],\n",
    "    system_prompt=\"\"\" You are an expert agent that can repond to queries related to expression evaluation and\n",
    "    TCS policies. You have access to \"calc_agent_tool\", and \"rag_policy_agent_tool\" to provide responses to\n",
    "    expression evaluation and TCS policies respectively.\n",
    "\n",
    "    Donot hallicunate and respond.\n",
    "    Respond only with the information obtained from the tools available in hand. \n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# response = supervisor_agent.invoke({\"messages\": [{\"role\": \"human\", \"content\": \"query : Answer about TCS policies?\"}]})\n",
    "response = supervisor_agent.invoke({\"messages\": [{\"role\": \"human\", \"content\": \"query : 2*3-2?\"}]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "311d87e5-17b0-4368-9f0c-a96bd7bef485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human : query : 2*3-2?\n",
      "AI : \n",
      " suggested tool_calls : \n",
      " name : calc_agent_tool \n",
      " args : {'query': '2*3-2'}\n",
      "Tool : The result of \\(2 \\times 3 - 2\\) is \\(4\\).\n",
      "AI : The result of the expression \\(2 \\times 3 - 2\\) is \\(4\\).\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "for message in response['messages']:\n",
    "    if(type(message) == HumanMessage):\n",
    "        print(f\"Human : {message.content}\")\n",
    "    elif(type(message) == SystemMessage):\n",
    "        print(f\"System : {message.content}\")\n",
    "    elif(type(message) == AIMessage):\n",
    "        if(message.content == ''):\n",
    "            print(f\"AI : \\n suggested tool_calls : \\n name : {message.tool_calls[0]['name']} \\n args : {message.tool_calls[0]['args']}\")\n",
    "        else:\n",
    "            print(f\"AI : {message.content}\")\n",
    "    elif(type(message) == ToolMessage):\n",
    "        print(f\"Tool : {message.content}\")\n",
    "    # print(type(message) , message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14677d0a-9cff-4088-9ebf-da08076bf06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Prompt: 2*3-2\n",
      "AI Response: \n",
      " suggested tool_calls : \n",
      " name : multiplication \n",
      " args : {'a': 2, 'b': 3}\n",
      "AI Response: \n",
      " suggested tool_calls : \n",
      " name : subtraction \n",
      " args : {'a': 6, 'b': 2}\n",
      "Tool Resposne: 6.0\n",
      "Tool Resposne: 4.0\n",
      "AI Response: The result of \\(2 \\times 3 - 2\\) is \\(4\\).\n"
     ]
    }
   ],
   "source": [
    "for message in all_calls[0]['messages']:\n",
    "    if(type(message) == HumanMessage):\n",
    "        print(f\"Human Prompt: {message.content}\")\n",
    "    elif(type(message) == SystemMessage):\n",
    "        print(f\"System Prompt: {message.content}\")\n",
    "    elif(type(message) == AIMessage):\n",
    "        if(message.content == ''):\n",
    "            if(len(message.tool_calls) >1):\n",
    "                for i in range(len(message.tool_calls)):\n",
    "                    print(f\"AI Response: \\n suggested tool_calls : \\n name : {message.tool_calls[i]['name']} \\n args : {message.tool_calls[i]['args']}\")\n",
    "            else:\n",
    "                print(f\"AI Response: \\n suggested tool_calls : \\n name : {message.tool_calls[0]['name']} \\n args : {message.tool_calls[0]['args']}\")\n",
    "        else:\n",
    "            print(f\"AI Response: {message.content}\")\n",
    "    elif(type(message) == ToolMessage):\n",
    "        print(f\"Tool Resposne: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e67eb54e-ffcc-4cc0-8bca-f9001a0313c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [HumanMessage(content='2*3-2', additional_kwargs={}, response_metadata={}, id='95f3332c-d8ba-48a3-8703-a9c3a43978a3'),\n",
       "   AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 1310, 'total_tokens': 1363, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgEoX6vZ1KBq2cxhAHAV5lIpz5OGP', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f0544469-9357-4dc0-a6f4-083aa2ed5157-0', tool_calls=[{'name': 'multiplication', 'args': {'a': 2, 'b': 3}, 'id': 'call_wtovDtSJ4tlzEkkqtCDehfOw', 'type': 'tool_call'}, {'name': 'subtraction', 'args': {'a': 6, 'b': 2}, 'id': 'call_Zlx79BD5jpFwF0GSyeTHXjNK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1310, 'output_tokens': 53, 'total_tokens': 1363, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='6.0', name='multiplication', id='201099c2-88a2-4c9a-9d7d-dd4de7c13475', tool_call_id='call_wtovDtSJ4tlzEkkqtCDehfOw'),\n",
       "   ToolMessage(content='4.0', name='subtraction', id='467c65be-3e65-46d5-9c7a-611609028ffd', tool_call_id='call_Zlx79BD5jpFwF0GSyeTHXjNK'),\n",
       "   AIMessage(content='The result of \\\\(2 \\\\times 3 - 2\\\\) is \\\\(4\\\\).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 1383, 'total_tokens': 1403, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CgEoZjQ74qLmc6roNR4vjlss3d23B', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--330973bd-34b4-4bb2-b09e-be31ba054f9d-0', usage_metadata={'input_tokens': 1383, 'output_tokens': 20, 'total_tokens': 1403, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97377faf-1d87-419d-af70-d2eb369992f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls=[{'name': 'multiplication', 'args': {'a': 2, 'b': 3}, 'id': 'call_wtovDtSJ4tlzEkkqtCDehfOw', 'type': 'tool_call'}, {'name': 'subtraction', 'args': {'a': 6, 'b': 2}, 'id': 'call_Zlx79BD5jpFwF0GSyeTHXjNK', 'type': 'tool_call'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b0b01cf-fcb1-4b15-8740-01b65886eddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('multiplication', {'a': 2, 'b': 3}, 'subtraction', {'a': 2, 'b': 3})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls[0]['name'], tool_calls[0]['args'], tool_calls[1]['name'], tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cdf8e-b43d-4d88-a75e-5e4d01a94037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e646189-4dd7-4d11-81d4-aeca823f7b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cca8f0-3797-4c1b-bc8b-7150bebbbf54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9a8e5-a5c3-48b6-8b8e-d5592cc4b56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
